{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Here we focus on three classifiers: logistic regression, linear discriminant, and quadratic discriminant. We will apply each classifier in two steps:\n",
    "\n",
    "- When there is only one predictor.\n",
    "- When there are two or more predictors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file\n",
    "Load credit data set. \n",
    "for excel files pandas library is used\n",
    "- pandas function `pd.read_csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path='data/'\n",
    "filename = path+'Default.xlsx'\n",
    "default_data = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "default_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Factorize\n",
    "Machine learning algorithms cannot function with string variables. We need to transform 'Yes' and 'No' to some numerical values. For binary variables it is convenient to transform the categories to zero and one. Let's transform 'No' to zero and 'Yes' to one before going further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data['default_factor'] = default_data.default.factorize()[0]\n",
    "default_data['student_factor'] = default_data.student.factorize()[0]\n",
    "\n",
    "default_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple logistic regression\n",
    "Here we predict the default status 'No'=0 or 'Yes' only based on credit balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you feed the data in the right shape  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = default_data[['balance']]\n",
    "y = default_data['default_factor']\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_pred = np.array([1500, 2000]).reshape(2,1)\n",
    "\n",
    "print(X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.predict_proba(X_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.predict(X_pred).reshape(2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.linspace(start = 0, stop = 3000, num= 100).reshape(-1,1)\n",
    "y_pred = lr.predict_proba(X_pred)\n",
    "#y_pred = (1+np.exp(-(lr.intercept_ + lr.coef_*X_pred)))**(-1)\n",
    "#X_pred.shape\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(X, y, 'or', mfc='none');\n",
    "plt.plot(X_pred, y_pred[:,1], '-b');\n",
    "plt.xlabel('Balance');\n",
    "plt.ylabel('Probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how precise the predictor is\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = lr.predict(X)\n",
    "#print(y_pred)\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson\n",
    "Logistic regression tends to favour over-represented class\n",
    "# Remedy\n",
    "Cut the probability at the right point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (lr.predict_proba(X)[:,1]>0.03)*1\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "log_fpr, log_tpr, log_thresholds = roc_curve(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "log_AUC = roc_auc_score(y, y_pred)\n",
    "\n",
    "print('AUC:%.3f'% log_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log_fpr, log_tpr,'r-',label = 'LOG AUC: %.3f'%log_AUC)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k-',label='random')\n",
    "plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')\n",
    "plt.legend()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant\n",
    "Linear discriminant analysis (lda) is one of the most popular classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# Make sure you feed the data in the right shape  \n",
    "X = default_data[['balance']]\n",
    "y = default_data['default_factor']\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_pred = np.array([1500, 2000]).reshape(2,1)\n",
    "print(X_pred)\n",
    "print(lda.predict_proba(X_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X_pred = np.linspace(start = 0, stop = 3000, num= 100).reshape(-1,1)\n",
    "y_pred = lda.predict_proba(X_pred)\n",
    "plt.plot(X, y, 'or', mfc='none')\n",
    "plt.plot(X_pred, y_pred[:,1], '-b')\n",
    "plt.xlabel('Balance')\n",
    "plt.ylabel('Probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = lda.predict(X)\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson\n",
    "Linear discriminant is a bit better in the case of unbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (lda.predict_proba(X)[:,1]>0.03)*1\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant\n",
    "Quadratic discriminant functions the same as the linear discriminant. Here we only repeat the codes above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# Make sure you feed the data in the right shape  \n",
    "X = default_data[['balance']]\n",
    "y = default_data['default_factor']\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.array([1500, 2000]).reshape(-1,1)\n",
    "print(qda.predict_proba(X_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = qda.predict(X)\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (qda.predict_proba(X)[:,1]>0.03)*1\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two predictors (or more)\n",
    "Fitting the logistic regression with two predictors is very similar to simple version. Just feed the appropriate matrix X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = default_data[['balance', 'income']]\n",
    "y = default_data['default_factor']\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.array([1500, 20000, 1500, 25000]).reshape(2,2)\n",
    "print(X_pred)\n",
    "print(lr.predict_proba(X_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with statsmodels\n",
    "Always statsmodels provides more statistical details. Let's try fitting logistic regression with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "lr = smf.Logit.from_formula(formula = \"default_factor~balance+income\", \n",
    "                            data= default_data).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
